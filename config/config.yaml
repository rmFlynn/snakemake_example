# You will want to fill this out for each run, it should be fine to clone this repo for each run.
type: 'meta_t' # type can be 'meta_t' or 'meta_g'
inputs:
  interleaved_reads: 
    # these need to be formated like below with - at the start
    #  - /home/projects-wrighton/NIH_Salmonella/Salmonella/Metatranscriptomics/SalmonellaMetaTreads/raw_reads_for_RMNP_validation/interleaved/*.fastq ###Kai- got error trying to run with paired_reads so had to interleave to make work
     #>- read1.fastq
     #>- read2.fastq
     # alternately
     #>- folder/path/*.fastq
  paired_reads: 
     - /home/projects-wrighton/NIH_Salmonella/Salmonella/Metatranscriptomics/SalmonellaMetaTreads/raw_reads_for_RMNP_validation/*.fastq ###Kai- got error trying to run with paired_reads so had to interleave to make work
    #- '/path/one/name1*.fastq*'
    #- '/path/two/name2*.fastq*'
  named_reads: 
  # Here you can put nothing, or asmany reads as you want with the format: 
  any_name_you_want: 
    #>31: something_R1.fastq.gz
    #>R2: something_R2.fastq.gz 
    # Alternately
    #>inter: something_interleaved.fastq.gz
  # This is one database file should it be more?
  # You set both the input and output for the database, that bowtie2 will use. These files may be used for many
  # analisies so the output file can be in a central location so it dose not need to be remade. 
  bowtie2_database_raw: /home/projects-wrighton/NIH_Salmonella/Salmonella/Metagenomes/MAG_database/MQ_HQ_bins/drep_out_all_final/dereplicated_genomes/mag_id/DRAM/scaffolds.fna
  bowtie2_database_built: /home/projects-wrighton/NIH_Salmonella/Salmonella/Metatranscriptomics/SalmonellaMetaTreads/RMNP_validation/RMNP_pipline-main/bowtie_2_db/db # The permanent home for the database
  gff: /home/projects-wrighton/NIH_Salmonella/Salmonella/Metagenomes/MAG_database/MQ_HQ_bins/drep_out_all_final/dereplicated_genomes/mag_id/DRAM/genes.gff # only for meta-t

outputs:
  get_quality: False
  get_counts: True
  get_stats: False
  get_bams: True 
  get_coverm: False
# You will probably not use this part 75% of the time.
binning:
  forward_id: '_R1'
  backward_id: '_R2'
  sickle_quality_type: 'sanger' # options include 'sanger' and 'illumina' 
coverm:
  min_read_percent_identity_pair: 0.95
  min_covered_fraction: 0.75
  min_depth: 3
  genome_fasta_extension: 'fa'
  sequence_lenth: 100
  calculate_per_seq_length: False
  fasta_dir: the/dir/of/fastas # only for meta-g ###Kai-cant run metaT without this param
counting:
  percent_read: 95 # For Rich sam_file.py: percent of (read_length - mismatches)/read_length to keep EX: 90
  max_mismatch: 3 # For Rich sam_file.py: max number of mismatches
  featuretype: 'CDS' # For workflow/scripts/flexcount.py: Feature type (3rd column in GTF file) to be used, all features of other type are ignored
  stranded: 'reverse'
  idattr: 'ID' # For workflow/scripts/flexcount.py: GTF attribute to be used as feature ID (default, suitable for Ensemble GTF files: gene_id). 
backend:
  report: "report/workflow.rst"
  check_fasta_for_dups: True

###Kai - had to add all of htis from Rory's example_config.yaml to make work
cluster: # This section will set variables for slurm from those set for jobs in Snakemake
  mkdir -p logs/{rule} &&
  sbatch
    --partition={resources.partition}
    --ntasks={threads}
    --mem={resources.mem}
    --job-name=smk-{rule}-{wildcards}
    --output=logs/{rule}/{rule}-{wildcards}-%j.out
    --mail-type={resources.mail_type}
    --mail-user={resources.mail_user}
    # --nodelist="zenith" # If this is set things will run only on zenith
default-resources: # These are defaults, Snakemake will overide them, so they should be low
  - partition=wrighton-hi,wrighton-low # Default partition for your lab or debug for me
  - ntasks=1
  - node=1
  - mem=100
  - time="14:00:00"
  - mail_user="ileleiwi@colostate.edu" # set your email
  - mail_type="FAIL"
# Defaults for Snakemake, not Slurm
restart-times: 0 # number of times to restart failing jobs (default 0)
max-jobs-per-second: 5 # max_jobs_per_second
max-status-checks-per-second: 1 # How often the run is checked
local-cores: 1 #  the number of provided local cores if in cluster mode (ignored without cluster support) (default 1)
jobs: 1
latency-wait: 60
keep-going: False
rerun-incomplete: False
printshellcmds: True
scheduler: greedy
use-conda: True # Even if you don't use conda this must be set
conda-prefix: '~/snake_conda_env'


