# You will want to fill this out for each run, it should be fine to clone this repo for each run.
inputs:
  # This can be a set of wild cards, or a list
  paired_reads:
    # - resources/tini*
    #- test_data/vari_size_inputs/*fastq.gz
    #- /home/projects-wrighton-2/projects-flynn/test_data/16_S3S*
    #- /home/ORG-Data-2/EMERGE/2016_27metaT/16_S3S*
    - /home/ORG-Data-2/EMERGE/2016_27metaT/3_E1D* 
  # This is one database file should it be more?
  # You set both the input and output for the database, that bowtie2 will use. These files may be used for many
  # analisies so the output file can be in a central location so it dose not need to be remade. 
  bowtie2_database_raw: /home/projects-wrighton/EMERGE/EMERGE_metaTs/2016/concat_mapping/97dRep_scaffolds_combined.fa 
  bowtie2_database_built: resources/bowtie2_databases/full_db
    # bowtie2_database_raw:  test_data/vari_size_inputs/database_3412_size.fa
    # bowtie2_database_built: resources/bowtie2_databases/database_3412_cores_10
  gff: /home/projects-wrighton/EMERGE/EMERGE_metaTs/2016/concat_mapping/drep_genes_combined.gff
# You will probably not use this part 75% of the time.
binning:
  forward_id: '_R1'
  backward_id: '_R2'
counting:
  percent_read: 95 # For Rich sam_file.py: percent of (read_length - mismatches)/read_length to keep EX: 90
  max_mismatch: 3 # For Rich sam_file.py: max number of mismatches
  featuretype: 'CDS' # For workflow/scripts/flexcount.py: Feature type (3rd column in GTF file) to be used, all features of other type are ignored
  idattr: 'ID' # For workflow/scripts/flexcount.py: GTF attribute to be used as feature ID (default, suitable for Ensembl GTF files: gene_id). 
backend:
  report: "report/workflow.rst"


